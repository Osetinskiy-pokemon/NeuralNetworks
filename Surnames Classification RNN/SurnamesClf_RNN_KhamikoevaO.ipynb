{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKMq7dp2W15Y",
        "outputId": "b0b91b97-e7ce-4466-85c6-be6a94fefa9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import typing as t\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm-QilGISxkt"
      },
      "source": [
        "## 1. Классификация фамилий (RNN)\n",
        "\n",
        "Датасет: https://disk.yandex.ru/d/frNchuaBQVLxyA?w=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn7TymjJeO7E",
        "outputId": "ba62f5c1-3876-4a8c-aef9-73e549422fde"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdPr92i6k-If"
      },
      "source": [
        "1.1 Используя класс `nn.RNNCell` (абстракцию для отдельного временного шага RNN), реализуйте простейшую рекуррентную сеть Элмана в виде класса `RNN`. Используя созданный класс `RNN`, решите задачу классификации фамилий. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "surnames_df=pd.read_csv('drive/MyDrive/ML_FU/Lab_7/data/surnames.csv')\n",
        "surnames_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zT6HPHuxeViN",
        "outputId": "d5e1bc18-5e12-4d19-e7fe-40dae4f33632"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    surname nationality\n",
              "0  Woodford     English\n",
              "1      Coté      French\n",
              "2      Kore     English\n",
              "3     Koury      Arabic\n",
              "4    Lebzak     Russian"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-accd7e18-3b7d-4087-813c-846dca8c93f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>surname</th>\n",
              "      <th>nationality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Woodford</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coté</td>\n",
              "      <td>French</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kore</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Koury</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Lebzak</td>\n",
              "      <td>Russian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-accd7e18-3b7d-4087-813c-846dca8c93f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-accd7e18-3b7d-4087-813c-846dca8c93f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-accd7e18-3b7d-4087-813c-846dca8c93f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# поделим выборку на тестовую и обучающую \n",
        "X_train, X_test, y_train, y_test = train_test_split(surnames_df['surname'].values, surnames_df['nationality'].values, test_size=0.2, random_state=123)\n",
        "print(f'Размер обучающей выборки: {len(X_train)} \\nРазмер тестовой выборки: {len(X_test)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PyVX8dPejE0",
        "outputId": "b8630a26-8544-4564-86c5-ae31e051be67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающей выборки: 8784 \n",
            "Размер тестовой выборки: 2196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# формирование словарь и добавляем токены\n",
        "class Vocab:\n",
        "    \n",
        "  def __init__(self, data):\n",
        "    surnames = data[\"surname\"]\n",
        "    self.nationalities = list(set(data[\"nationality\"])) #берем все национальности\n",
        "    self.nationality_to_idx = dict(zip(self.nationalities, range(len(self.nationalities)))) #формируем словарь\n",
        "    self.rexp = re.compile(r'[\\s\\n\\t]+') #регулярное выражение\n",
        "    self.index_to_token = [\"<PAD>\", \"<UNK>\"] #необходимые токены\n",
        "    self.token_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "    self.max_seq_len = 0 #здесь будет храниться максимальная длина последовательности\n",
        "    for surname in surnames:\n",
        "      surname = self.rexp.sub('', surname).lower()\n",
        "      for i, token in enumerate(surname, start=1):\n",
        "        self.max_seq_len = max(self.max_seq_len, i)\n",
        "        if not(token in self.token_to_idx):\n",
        "          self.token_to_idx[token] = len(self.index_to_token)\n",
        "          self.index_to_token.append(token)\n",
        "                    \n",
        "  def __len__(self):\n",
        "    return len(self.index_to_token)"
      ],
      "metadata": {
        "id": "ySDNEc2hfeVB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SurnameDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y, vocab: Vocab):\n",
        "    self.vocab = vocab\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def vectorize(self, surname):\n",
        "    seq_t = torch.zeros(self.vocab.max_seq_len).to(torch.int64)\n",
        "    surname = self.vocab.rexp.sub('', surname).lower()\n",
        "    for i, t in enumerate(surname):\n",
        "      try:\n",
        "        seq_t[i] = self.vocab.token_to_idx.get(t, 1)\n",
        "      except IndexError:\n",
        "        break\n",
        "    return seq_t\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    surname = self.X[index]\n",
        "    nationality = self.y[index]\n",
        "    return self.vectorize(surname), self.vocab.nationality_to_idx[nationality]"
      ],
      "metadata": {
        "id": "H1tMpbr1iyXb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Vocab(surnames_df) # преобразуем в словарь"
      ],
      "metadata": {
        "id": "sHHSQBPHkBU9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# разделяем на обучающую и тестовую выборки\n",
        "train_data = SurnameDataset(X_train, y_train, vocab)\n",
        "test_data = SurnameDataset(X_test, y_test, vocab)\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, drop_last=True)"
      ],
      "metadata": {
        "id": "tRmWxA3tkDeJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#проверим, что все получилось\n",
        "test_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5IpLfPXkhTR",
        "outputId": "5db62200-bc27-4e75-9973-c1b4409b2bdd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 3,  7, 20, 18, 17, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
              " 15)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNNCell:"
      ],
      "metadata": {
        "id": "H9ScVPN6lmLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    \n",
        "  def __init__(self, input_size, hidden_size, num_embeddings, n_classes, aggregate=False):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.hidden_state_history = None\n",
        "    self.aggregate_flag = aggregate\n",
        "        \n",
        "    #эмбеддинг   \n",
        "    self.embedding = nn.Embedding.from_pretrained(\n",
        "    embeddings=torch.tensor([list(map(lambda x: float(x), row.split()[1:])) for row in open('drive/MyDrive/ML_FU/Lab_7/data/globe_100_rows.txt').readlines()], dtype=torch.float32), freeze=False, padding_idx=0)\n",
        "    self.rnn_cell = nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)\n",
        "    self.fc = nn.Linear(hidden_size, n_classes)\n",
        "\n",
        "    #здесь инициализируется тензор скрытых состояний\n",
        "  def forward(self, x, h=None):\n",
        "    self.hidden_state_history = torch.empty(x.shape[0], x.shape[1], self.hidden_size)\n",
        "    x = self.embedding(x)\n",
        "    if h is None:\n",
        "      h = torch.randn(x.shape[0], self.hidden_size, requires_grad=True)\n",
        "\n",
        "      # затем обновляется скрытое состояние при прохождении по каждому элементу последовательностей s в батче\n",
        "    for i in range(x.shape[1]):\n",
        "      h = self.rnn_cell(x[:, i, :], h)\n",
        "      self.hidden_state_history[:, i, :] = h\n",
        "    if self.aggregate_flag:\n",
        "      h = torch.sum(self.hidden_state_history, dim=1)\n",
        "    classes_logits = self.fc(h)\n",
        "    return classes_logits, self.hidden_state_history, h # возвращать будем тензор всех наблюдавшихся скрытых состояний размера (batch_size, seq_len, hidden_size), а также и тензор скрытых состояний"
      ],
      "metadata": {
        "id": "w1wllC5QlvMF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель\n",
        "model_rnn_cell = RNN(\n",
        "    input_size=50,\n",
        "    hidden_size=32,\n",
        "    num_embeddings=len(vocab.index_to_token),\n",
        "    n_classes=len(vocab.nationality_to_idx),\n",
        "    aggregate=True\n",
        ")\n",
        "\n",
        "optimizer_rnn_cell = optim.Adam(model_rnn_cell.parameters(), lr=0.0005) # оптимизатор обновляет веса моделей на основании ошибки\n",
        "loss_fn = nn.CrossEntropyLoss() # функция ошибки"
      ],
      "metadata": {
        "id": "OwaX5cDfm4sp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(preds, a): # получение точности\n",
        "  return torch.sum(torch.argmax(torch.softmax(preds, dim=1), dim=1) == a) / len(a)"
      ],
      "metadata": {
        "id": "FL7vCI_IrffG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_epochs, train_loader, test_loader, model, loss_fn, optimizer, printing):\n",
        "  for epoch in range(n_epochs):\n",
        "    accuracy = 0\n",
        "    losses = 0\n",
        "    model.train() # задаем модели состояние \"будем обучать\"\n",
        "    for x_batch, y_batch in train_loader:\n",
        "      pred = model(x_batch)[0] # вызываем forward\n",
        "      loss = loss_fn(pred, y_batch) # считаем ошибку     \n",
        "      \n",
        "      optimizer.zero_grad() # это чтобы сбросить состояние оптимизатора\n",
        "      loss.backward() # обратное распространение ошибки\n",
        "      optimizer.step() # устанавливаем новые веса\n",
        "      losses += loss.item()\n",
        "      accuracy += get_accuracy(pred, y_batch)\n",
        "    losses /= len(train_loader)\n",
        "    accuracy /= len(train_loader)\n",
        "    if (epoch + 1) % printing == 0:\n",
        "      test_accuracy = 0.0\n",
        "      test_losses = 0.0\n",
        "      model.eval() # перевод состояния модели в \"не будем обучать\"\n",
        "      # производим подсчет показателей на тесте\n",
        "      for x_batch, y_batch in test_loader:\n",
        "        test_pred = model(x_batch)[0]\n",
        "        test_acc = get_accuracy(test_pred, y_batch)\n",
        "        test_loss = loss_fn(test_pred, y_batch)\n",
        "        test_accuracy += test_acc\n",
        "        test_losses += test_loss\n",
        "      test_accuracy /= len(test_loader)\n",
        "      test_losses /= len(test_loader)\n",
        "      print(\"_\" * 40)\n",
        "      print('Train:')\n",
        "      print(f'Loss: {losses}, Accuracy: {accuracy}')\n",
        "      print(\"-\" * 40)\n",
        "      print('Test:')            \n",
        "      print(f'Loss: {test_losses}, Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "wvI2U67TppaK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(100, train_loader, test_loader, model_rnn_cell, loss_fn, optimizer_rnn_cell, printing=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o71OXgPAqfSr",
        "outputId": "b346ebd1-5eaf-493c-ffa4-ed08674a068c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.7924162846629637, Accuracy: 0.7658531069755554\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.9018857479095459, Accuracy: 0.732536792755127\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.7699961349041793, Accuracy: 0.7697308659553528\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.876166820526123, Accuracy: 0.7421875\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.7618763303778467, Accuracy: 0.7740647792816162\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8750185966491699, Accuracy: 0.7431066036224365\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.7306746935648639, Accuracy: 0.7803375720977783\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8944239616394043, Accuracy: 0.7426470518112183\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.7119454021436454, Accuracy: 0.7814781069755554\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8787550926208496, Accuracy: 0.7412683963775635\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.7074605484839773, Accuracy: 0.7856979966163635\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.873381495475769, Accuracy: 0.7545955777168274\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6945367108513839, Accuracy: 0.7872946858406067\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8650920987129211, Accuracy: 0.7486213445663452\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6852371195045701, Accuracy: 0.7899178862571716\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8529307842254639, Accuracy: 0.7564338445663452\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6727215071229169, Accuracy: 0.7908303141593933\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8709290623664856, Accuracy: 0.7545955777168274\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.668925064976198, Accuracy: 0.790145993232727\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8686336278915405, Accuracy: 0.7522978186607361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def curr_accuracy_m(model): # определение итоговой точности модели\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "      out = model(X_batch)[0]\n",
        "      _, pred = torch.max(out, dim=1)\n",
        "      total += y_batch.shape[0]\n",
        "      correct += int((pred == y_batch).sum())\n",
        "  print(correct / total)"
      ],
      "metadata": {
        "id": "us0_cbU31V35"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_accuracy_m(model_rnn_cell)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNReUbr2o1q-",
        "outputId": "1e9f65d8-c413-437f-943d-dcbccfac990a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7490808823529411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность модели 75%."
      ],
      "metadata": {
        "id": "MxpuSI3O_pcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def total_conclusion(surname, model):\n",
        "  new_surname = train_data.vectorize(surname)\n",
        "  new_surname = new_surname.unsqueeze(dim=0)\n",
        "  with torch.inference_mode():\n",
        "    model.eval()\n",
        "    print(f'{surname} --> {vocab.nationalities[torch.argmax(model(new_surname)[0], dim=1).item()]}')"
      ],
      "metadata": {
        "id": "pVg27tPnx8WN"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка\n",
        "students_PI19_3 = [\n",
        "  \"Alexandrova\",\n",
        "  \"Baranov\",\n",
        "  \"Brusova\",\n",
        "  \"Volkova\",\n",
        "  \"Gasanova\",\n",
        "  \"Danilin\",\n",
        "  \"Demenchuk\",\n",
        "  \"Egorov\",\n",
        "  \"Popova\",\n",
        "  \"Polikarpova\",\n",
        "  \"Khamikoeva\",\n",
        "]\n",
        "\n",
        "for surname in students_PI19_3:\n",
        "  total_conclusion(surname=surname, model=model_rnn_cell)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IZ9KF7Qy8D2",
        "outputId": "486d4ca6-bc06-49ae-afd9-a00a91759806"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alexandrova --> Italian\n",
            "Baranov --> Russian\n",
            "Brusova --> Czech\n",
            "Volkova --> Czech\n",
            "Gasanova --> Spanish\n",
            "Danilin --> Russian\n",
            "Demenchuk --> Russian\n",
            "Egorov --> Russian\n",
            "Popova --> Czech\n",
            "Polikarpova --> Czech\n",
            "Khamikoeva --> Russian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2MIErKTo9aO"
      },
      "source": [
        "1.2 Замените модуль `RNN` из 1.1 на модули `nn.RNN`, `nn.LSTM` и `nn.GRU` (не забудьте указать аргумент `batch_first=True`). Сравните результаты работы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiEW6urQeHu4"
      },
      "source": [
        "### nn.RNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_rnn(nn.Module):\n",
        "    \n",
        "  def __init__(self, input_size, hidden_size, n_layers, num_embeddings, n_classes, aggregate: bool = False):\n",
        "    super(RNN_rnn, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = n_layers\n",
        "    self.aggregate_flag = aggregate \n",
        "        \n",
        "    # загрузка предобученного эмбендинга из п.1.3.\n",
        "\n",
        "    self.embedding = nn.Embedding.from_pretrained(embeddings=torch.tensor([list(map(lambda x: float(x), row.split()[1:])) for row in open('drive/MyDrive/ML_FU/Lab_7/data/globe_100_rows.txt').readlines()], dtype=torch.float32), freeze=False, padding_idx=0)\n",
        "    self.rnn_block = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=self.n_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size * self.n_layers, n_classes)\n",
        "\n",
        "  def forward(self, x, h=None):\n",
        "    x = self.embedding(x)\n",
        "    all_h, h = self.rnn_block(x, h)\n",
        "    h = h.permute(1, 0, 2)\n",
        "    if self.aggregate_flag:\n",
        "      h = torch.sum(all_h, dim=1)\n",
        "    else:\n",
        "      h = torch.flatten(h, start_dim=1, end_dim=-1)\n",
        "    classes_logits = self.fc(h)\n",
        "    return classes_logits, all_h, h"
      ],
      "metadata": {
        "id": "CjZY3rBZzsDD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn = RNN_rnn( \n",
        "    input_size=50,\n",
        "    hidden_size=32,\n",
        "    n_layers=1,\n",
        "    num_embeddings=len(vocab.index_to_token),\n",
        "    n_classes=len(vocab.nationality_to_idx),\n",
        "    aggregate=True\n",
        ")\n",
        "optimizer_rnn = optim.Adam(model_rnn.parameters(), lr=0.001) # оптимизатор обновляет веса моделей на основании ошибки\n",
        "loss_fn = nn.CrossEntropyLoss() # функция потерь"
      ],
      "metadata": {
        "id": "f6S6DjvE0X7L"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(100, train_loader, test_loader, model_rnn, loss_fn, optimizer_rnn, printing=10) # обучение"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--PHT09h0uLd",
        "outputId": "11094fae-2c45-462a-fddf-46388b89c5bf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________________________________________\n",
            "Train:\n",
            "Loss: 1.1816601634678179, Accuracy: 0.6418795585632324\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.2699986696243286, Accuracy: 0.6240808963775635\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.9349972747103141, Accuracy: 0.72661954164505\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.0158412456512451, Accuracy: 0.7063419222831726\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.8200940758424954, Accuracy: 0.7512545585632324\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.9346230626106262, Accuracy: 0.724724292755127\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.7578400999960238, Accuracy: 0.7712135314941406\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8846026659011841, Accuracy: 0.748161792755127\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6968776715824204, Accuracy: 0.7863823175430298\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8704829216003418, Accuracy: 0.7463235259056091\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6637745850386411, Accuracy: 0.7967609763145447\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.869452714920044, Accuracy: 0.7545955777168274\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6322320129749549, Accuracy: 0.8014370203018188\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8817461729049683, Accuracy: 0.7421875\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6171608664041018, Accuracy: 0.8070255517959595\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.9267667531967163, Accuracy: 0.7477021813392639\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.585563133776623, Accuracy: 0.8163777589797974\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.9230120778083801, Accuracy: 0.734375\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.577378947260606, Accuracy: 0.8191149830818176\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.9118799567222595, Accuracy: 0.7449448704719543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_accuracy_m(model_rnn) # итоговая точность"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCciAq621z6Q",
        "outputId": "a2fc16c0-8ede-42d7-8d4d-49fa2a2a1f58"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7449448529411765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Точность модели 74%.**"
      ],
      "metadata": {
        "id": "1hWkUBhABEQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка на примерах\n",
        "for surname in students_PI19_3:\n",
        "  total_conclusion(surname=surname, model=model_rnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkNgT5At1Y2N",
        "outputId": "722eef77-f0bb-4c8d-ac81-5274624e9f91"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alexandrova --> Spanish\n",
            "Baranov --> Russian\n",
            "Brusova --> Czech\n",
            "Volkova --> Czech\n",
            "Gasanova --> Russian\n",
            "Danilin --> Russian\n",
            "Demenchuk --> Russian\n",
            "Egorov --> Russian\n",
            "Popova --> Czech\n",
            "Polikarpova --> Greek\n",
            "Khamikoeva --> English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8jKuMq5eHu8"
      },
      "source": [
        "## nn.LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    \n",
        "  def __init__(self, input_size, hidden_size, n_layers, num_embeddings, n_classes, aggregate=False):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = n_layers\n",
        "    self.aggregate_flag = aggregate\n",
        "        \n",
        "\n",
        "        # загрузка предобученного эмбендинга из п.1.3.\n",
        "\n",
        "    self.embedding = nn.Embedding.from_pretrained(embeddings=torch.tensor([list(map(lambda x: float(x), row.split()[1:])) for row in open('drive/MyDrive/ML_FU/Lab_7/data/globe_100_rows.txt').readlines()], dtype=torch.float32), freeze=False, padding_idx=0)\n",
        "    self.rnn_block = nn.LSTM(\n",
        "        input_size=input_size,\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=self.n_layers,\n",
        "        batch_first=True\n",
        "    )\n",
        "    self.fc = nn.Linear(hidden_size * self.n_layers, n_classes)\n",
        "\n",
        "  def forward(self, x, h=None, c=None):\n",
        "    x = self.embedding(x)\n",
        "    if h and c:\n",
        "      all_h, (h_n, c_n) = self.rnn_block(x, (h, c))\n",
        "    else:\n",
        "      all_h, (h_n, c_n) = self.rnn_block(x)\n",
        "    h = h_n.permute(1, 0, 2)\n",
        "    if self.aggregate_flag:\n",
        "      h = torch.sum(all_h, dim=1)\n",
        "    else:\n",
        "      h = torch.flatten(h, start_dim=1, end_dim=-1)\n",
        "    classes_logits = self.fc(h)\n",
        "    return classes_logits, all_h, h_n, c_n"
      ],
      "metadata": {
        "id": "SEyh0EPM2OT0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = LSTM(\n",
        "    input_size=50,\n",
        "    hidden_size=32,\n",
        "    n_layers=1,\n",
        "    num_embeddings=len(vocab.index_to_token),\n",
        "    n_classes=len(vocab.nationality_to_idx),\n",
        "    aggregate=True\n",
        ")\n",
        "\n",
        "optimizer_lstm = optim.Adam(model_lstm.parameters(), lr=0.00025) # оптимизатор\n",
        "loss_fn = nn.CrossEntropyLoss() # функция потерь"
      ],
      "metadata": {
        "id": "VR_5JvnK3k6n"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(100, train_loader, test_loader, model_lstm, loss_fn, optimizer_lstm, printing=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y4y2-6C37j2",
        "outputId": "1a0e9a47-28e6-465c-8641-6a76e22ebd5f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________________________________________\n",
            "Train:\n",
            "Loss: 1.2989819598023908, Accuracy: 0.619297444820404\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.328439712524414, Accuracy: 0.6148896813392639\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 1.0769135177570537, Accuracy: 0.6851049065589905\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.1302987337112427, Accuracy: 0.673713207244873\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.9461797128846176, Accuracy: 0.7229698896408081\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.0212701559066772, Accuracy: 0.6948529481887817\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.856815772226257, Accuracy: 0.7424726486206055\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.9392174482345581, Accuracy: 0.7215073704719543\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.7988362882259118, Accuracy: 0.754676103591919\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8919363021850586, Accuracy: 0.7380514740943909\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.755928141030952, Accuracy: 0.7689324617385864\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8749380707740784, Accuracy: 0.740349292755127\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.7190860944942836, Accuracy: 0.7780565619468689\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8433308601379395, Accuracy: 0.7545955777168274\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.685374429734954, Accuracy: 0.7848996520042419\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8354923725128174, Accuracy: 0.7463235259056091\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6528762206979042, Accuracy: 0.7969890236854553\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8615136742591858, Accuracy: 0.748161792755127\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6296110674738884, Accuracy: 0.8066834211349487\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8613277673721313, Accuracy: 0.7532169222831726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_accuracy_m(model_lstm) # итоговая точность"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqGjKgAw4hHW",
        "outputId": "442f09b5-30a8-4b87-ef36-5fd6df77f51a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7532169117647058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель показала точность = 75%"
      ],
      "metadata": {
        "id": "CQi2ns0-BzaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка на примерах\n",
        "for surname in students_PI19_3:\n",
        "  total_conclusion(surname=surname, model=model_lstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l8FL2I94WtU",
        "outputId": "227cec26-634c-4ffd-b439-40540d86dca3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alexandrova --> Czech\n",
            "Baranov --> Russian\n",
            "Brusova --> Czech\n",
            "Volkova --> Czech\n",
            "Gasanova --> Spanish\n",
            "Danilin --> Russian\n",
            "Demenchuk --> Russian\n",
            "Egorov --> Russian\n",
            "Popova --> Czech\n",
            "Polikarpova --> Czech\n",
            "Khamikoeva --> Russian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8vxgcGleHvA"
      },
      "source": [
        "### nn.GRU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    \n",
        "  def __init__(self, input_size, hidden_size, n_layers, num_embeddings, n_classes, aggregate=False):\n",
        "    super(GRU, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = n_layers\n",
        "    self.aggregate_flag = aggregate\n",
        "        \n",
        "# загрузка предобученного эмбендинга из п.1.3.\n",
        "        \n",
        "    self.embedding = nn.Embedding.from_pretrained(embeddings=torch.tensor([list(map(lambda x: float(x), row.split()[1:])) for row in open('drive/MyDrive/ML_FU/Lab_7/data/globe_100_rows.txt').readlines()], dtype=torch.float32), freeze=False, padding_idx=0)\n",
        "    self.rnn_block = nn.GRU(\n",
        "      input_size=input_size,\n",
        "      hidden_size=hidden_size,\n",
        "      num_layers=self.n_layers,\n",
        "      batch_first=True\n",
        "    )\n",
        "    self.fc = nn.Linear(hidden_size * self.n_layers, n_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x, h=None):\n",
        "    x = self.embedding(x)\n",
        "    if h:\n",
        "      all_h, h = self.rnn_block(x, (h, c))\n",
        "    else:\n",
        "      all_h, h = self.rnn_block(x)\n",
        "    h = h.permute(1, 0, 2)\n",
        "    if self.aggregate_flag:\n",
        "      h = torch.sum(all_h, dim=1)\n",
        "    else:\n",
        "      h = torch.flatten(h, start_dim=1, end_dim=-1)\n",
        "    classes_logits = self.fc(h)\n",
        "    return classes_logits, all_h, h"
      ],
      "metadata": {
        "id": "7VmmXkYV4vIk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = GRU(\n",
        "    input_size=50,\n",
        "    hidden_size=32,\n",
        "    n_layers=1,\n",
        "    num_embeddings=len(vocab.index_to_token),\n",
        "    n_classes=len(vocab.nationality_to_idx),\n",
        "    aggregate=True\n",
        ")\n",
        "optimizer_gru = optim.Adam(model_gru.parameters(), lr=0.00035) # оптимизатор\n",
        "loss_fn = nn.CrossEntropyLoss() # функция потери"
      ],
      "metadata": {
        "id": "c3A0wpHh7rMa"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(100, train_loader, test_loader, model_gru, loss_fn, optimizer_gru, printing=10) # обучение"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkKdOSQn731y",
        "outputId": "0803f5e9-e05c-4ea8-9fd9-aa0cc19199af"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________________________________________\n",
            "Train:\n",
            "Loss: 1.138289686537137, Accuracy: 0.666172444820404\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.1663275957107544, Accuracy: 0.6603860259056091\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.8975173664571595, Accuracy: 0.7335766553878784\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.0007020235061646, Accuracy: 0.7040441036224365\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.7701357183230184, Accuracy: 0.7693886756896973\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8976666331291199, Accuracy: 0.728400707244873\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6954400322950669, Accuracy: 0.788093090057373\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8578768372535706, Accuracy: 0.7486213445663452\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.6418624639946179, Accuracy: 0.8058850169181824\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8439155220985413, Accuracy: 0.7545955777168274\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.5988453533092555, Accuracy: 0.815579354763031\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8199086785316467, Accuracy: 0.7651654481887817\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.5655371390663795, Accuracy: 0.8255017995834351\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8341077566146851, Accuracy: 0.7633271813392639\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.5342429533165737, Accuracy: 0.8309762477874756\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8278345465660095, Accuracy: 0.7679228186607361\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.502439436958219, Accuracy: 0.8429516553878784\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8386052250862122, Accuracy: 0.7651654481887817\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.4788819616728455, Accuracy: 0.8477417826652527\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 0.8690645098686218, Accuracy: 0.7665441036224365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_accuracy_m(model_gru) # итоговая точность"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCEzIwU57-z7",
        "outputId": "19cc59a7-8314-4d17-dc56-82e301c4c70b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7665441176470589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Точность модели 77%.**"
      ],
      "metadata": {
        "id": "urYqhGiCDPEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка на примерах\n",
        "for surname in students_PI19_3:\n",
        "  total_conclusion(surname=surname, model=model_lstm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goraQneG8DI4",
        "outputId": "11ff0223-8a6b-4d1e-b454-1c565bfc8a2e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alexandrova --> Czech\n",
            "Baranov --> Russian\n",
            "Brusova --> Czech\n",
            "Volkova --> Czech\n",
            "Gasanova --> Spanish\n",
            "Danilin --> Russian\n",
            "Demenchuk --> Russian\n",
            "Egorov --> Russian\n",
            "Popova --> Czech\n",
            "Polikarpova --> Czech\n",
            "Khamikoeva --> Russian\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод\n",
        "\n",
        "Все модели показали отличную точность, однако лучшие показатели (точность, время обучения) у GRU."
      ],
      "metadata": {
        "id": "_v8_vcAa8Jqy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6YBam_3t-fO"
      },
      "source": [
        "1.3 Загрузите предобученные эмбеддинги (https://disk.yandex.ru/d/BHuT2tEXr_yBOQ?w=1) в модуль `nn.Embedding` и обучите модели из 1.2.\n",
        "\n",
        "Сделано выше."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7kf990U9Do-"
      },
      "source": [
        "## 2. Классификация новостей на основе заголовка\n",
        "\n",
        "Датасет: https://disk.yandex.ru/d/FN-EgWGIpyjLxQ?w=1\n",
        "<br>Эмбеддинги: https://nlp.stanford.edu/projects/glove/ (находите ссылку на архив\n",
        "glove.6B.zip, в нем несколько файлов с эмбеддингами слов, выбираете один из файлов в\n",
        "архиве)\n",
        "<br><br>2.1 Загрузите набор данных train.csv. Выполните предобработку столбца Title\n",
        "<br><br>2.2 На основе этих данных создайте датасет NewsDataset . Не забудьте добавить\n",
        "специальные токены <PAD> для дополнения последовательностей до нужной длины и\n",
        "<UNK> для корректной обработке ранее не встречавшихся токенов. В данной задаче\n",
        "рассматривайте отдельные слова как токены. Разбейте датасет на обучающее и\n",
        "валидационное множество.\n",
        "<br><br>2.3 Создайте модель для классификации, используя слой nn.Embedding и слой nn.RNN .\n",
        "эмбеддинги инициализируйте случайным образом\n",
        "не забудьте указать аргумент padding_idx для nn.Embedding\n",
        "<br><br>2.4 Переобучите модель, заменив слой nn.RNN на nn.LSTM и nn.GRU . Сравните качество\n",
        "на тестовой выборке. Результаты сведите в таблицу (модель/метрика качества на\n",
        "тестовом множестве).\n",
        "<br><br>2.5 Выполните пункты 2.3 и 2.4, используя предобученные эмбеддинги Glove.\n",
        "Прокомментируйте результат.\n",
        "Эмбеддинги из скачанного файла загрузите в виде двумерного тензора\n",
        "pretrained_embeddings .\n",
        "Обратите внимание, что номер строки в этом тензоре должен соответствовать\n",
        "токену (слову), имеющему такой индекс в вашем словаре.\n",
        "для слов, которых нет в файле с эмбеддингами, инициализуйте эмбеддинг\n",
        "случайным образом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65AVWKwzeHvR"
      },
      "source": [
        "## 2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DAYRxzmxeHvR"
      },
      "outputs": [],
      "source": [
        "def preprocess(text): # предобработка текста\n",
        "  result_text = re.sub(r'[^A-Za-z\\!\\?\\s]', r'', text.lower())\n",
        "  return result_text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('drive/MyDrive/ML_FU/Lab_7/data/train.csv') # затягиваем данные\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1ZEhg12eCWuX",
        "outputId": "45049474-7edf-4632-e4f0-66edfdf36442"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Class Index                                              Title  \\\n",
              "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
              "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
              "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
              "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
              "4            3  Oil prices soar to all-time record, posing new...   \n",
              "\n",
              "                                         Description  \n",
              "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
              "1  Reuters - Private investment firm Carlyle Grou...  \n",
              "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
              "3  Reuters - Authorities have halted oil export\\f...  \n",
              "4  AFP - Tearaway world oil prices, toppling reco...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca52e280-be15-4ffb-8a48-d21d17563fbc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Index</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca52e280-be15-4ffb-8a48-d21d17563fbc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca52e280-be15-4ffb-8a48-d21d17563fbc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca52e280-be15-4ffb-8a48-d21d17563fbc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles = [] # это мы будем добавлять предобработанный текст в наш датасет\n",
        "for i in range(len(data['Title'])):\n",
        "  titles.append(preprocess(data['Title'][i].strip('\\n')))\n",
        "data['Title'] = titles"
      ],
      "metadata": {
        "id": "YEHRGSCkCqCT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[:2000]\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mgtBhMWSDfed",
        "outputId": "ea099eca-bd5a-4ebf-9348-8a276e77d3ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Class Index                                              Title  \\\n",
              "0            3     wall st bears claw back into the black reuters   \n",
              "1            3  carlyle looks toward commercial aerospace reuters   \n",
              "2            3       oil and economy cloud stocks outlook reuters   \n",
              "3            3  iraq halts oil exports from main southern pipe...   \n",
              "4            3  oil prices soar to alltime record posing new m...   \n",
              "\n",
              "                                         Description  \n",
              "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
              "1  Reuters - Private investment firm Carlyle Grou...  \n",
              "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
              "3  Reuters - Authorities have halted oil export\\f...  \n",
              "4  AFP - Tearaway world oil prices, toppling reco...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2764f4e-8680-414d-9eaa-a1f3e801dd9d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Index</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>wall st bears claw back into the black reuters</td>\n",
              "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>carlyle looks toward commercial aerospace reuters</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>oil and economy cloud stocks outlook reuters</td>\n",
              "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>iraq halts oil exports from main southern pipe...</td>\n",
              "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>oil prices soar to alltime record posing new m...</td>\n",
              "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2764f4e-8680-414d-9eaa-a1f3e801dd9d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2764f4e-8680-414d-9eaa-a1f3e801dd9d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2764f4e-8680-414d-9eaa-a1f3e801dd9d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# делим данные на тестовую и обучающую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['Title'].values, data['Class Index'].values, test_size=0.2, random_state=123)\n",
        "print(f'Train size: {X_train.shape[0]}, test size: {X_test.shape[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKuSYFRVDlH_",
        "outputId": "a7b3272d-0798-4c20-b2f3-4e6170b1d3e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 1600, test size: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab: # создадим словарь с заголовками новостей\n",
        "  def __init__(self, data):\n",
        "    self.max_seq_len = 0\n",
        "    self.idx_to_token = [\"<PAD>\", \"<UNK>\"]\n",
        "    self.token_to_idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "    self.lemmatizer = WordNetLemmatizer() # для формирования лемм слов\n",
        "    for row in data:\n",
        "      for i, t in enumerate(word_tokenize(row), start=1):\n",
        "        t = self.lemmatizer.lemmatize(t)\n",
        "        if i > self.max_seq_len:\n",
        "          self.max_seq_len = i\n",
        "        if not(t in self.token_to_idx):\n",
        "          self.token_to_idx[t] = len(self.idx_to_token)\n",
        "          self.idx_to_token.append(t)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.idx_to_token)"
      ],
      "metadata": {
        "id": "T6-aoB49D2PN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewDataset(Dataset):\n",
        "  def __init__(self, X, y, vocab):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def vectorize(self, review):\n",
        "    vectorized = [0] * self.vocab.max_seq_len\n",
        "    for i, t in enumerate(word_tokenize(review)):\n",
        "      t = self.vocab.lemmatizer.lemmatize(t)\n",
        "      try:\n",
        "        vectorized[i] = self.vocab.token_to_idx.get(t, 1)\n",
        "      except IndexError:\n",
        "        break\n",
        "    return torch.tensor(vectorized, dtype=torch.int64)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x, y = self.X[idx], self.y[idx]\n",
        "    x = self.vectorize(x)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "QBqG3_z2Et1b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Vocab(X_train)"
      ],
      "metadata": {
        "id": "xNkEEjYZFRkF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rdata = NewDataset(X_train, y_train, vocab)\n",
        "test_rdata = NewDataset(X_test, y_test, vocab)\n",
        "train_rloader = DataLoader(train_rdata, batch_size=32, shuffle=True)\n",
        "test_rloader = DataLoader(test_rdata, batch_size=32)"
      ],
      "metadata": {
        "id": "hM6ULklGFT9K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_rnn(nn.Module):\n",
        "    \n",
        "  def __init__(self, input_size, hidden_size, n_layers, num_embeddings, n_classes, aggregate: bool = False):\n",
        "    super(RNN_rnn, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = n_layers\n",
        "    self.aggregate_flag = aggregate\n",
        "        \n",
        "    # загружаем предобученный эмбеддинг\n",
        "    self.embedding = nn.Embedding.from_pretrained(embeddings=torch.tensor([list(map(lambda x: float(x), row.split()[1:])) for row in open('drive/MyDrive/ML_FU/Lab_7/data/glove.6B.100d.txt').readlines()], dtype=torch.float32), freeze=False, padding_idx=0)\n",
        "    self.rnn_block = nn.RNN(\n",
        "      input_size=input_size,\n",
        "      hidden_size=hidden_size,\n",
        "      num_layers=self.n_layers,\n",
        "      batch_first=True\n",
        "    )\n",
        "    self.fc = nn.Linear(hidden_size * self.n_layers, n_classes)\n",
        "\n",
        "  def forward(self, x, h=None):\n",
        "    x = self.embedding(x)\n",
        "    all_h, h = self.rnn_block(x, h)\n",
        "    h = h.permute(1, 0, 2)\n",
        "    if self.aggregate_flag:\n",
        "      h = torch.sum(all_h, dim=1)\n",
        "    else:\n",
        "      h = torch.flatten(h, start_dim=1, end_dim=-1)\n",
        "    classes_logits = self.fc(h)\n",
        "    return classes_logits, all_h, h"
      ],
      "metadata": {
        "id": "GQGUB6_sFiHu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn = RNN_rnn(\n",
        "    input_size=100,\n",
        "    hidden_size=32,\n",
        "    n_layers=1,\n",
        "    num_embeddings=len(vocab.idx_to_token),\n",
        "    n_classes=len(vocab.token_to_idx),\n",
        "    aggregate=True\n",
        ")\n",
        "optimizer_rnn = optim.Adam(model_rnn.parameters(), lr=0.001) # оптимизатор\n",
        "loss_fn = nn.CrossEntropyLoss() # функция потерь"
      ],
      "metadata": {
        "id": "ifMRrmA_HYF5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(100, train_rloader, test_rloader, model_rnn, loss_fn, optimizer_rnn, printing=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_zf0sYKIBeo",
        "outputId": "1ae9f582-a7d1-4e32-ff7e-b32dfa4a48b8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.23933689758181573, Accuracy: 0.9325000047683716\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.003892183303833, Accuracy: 0.6177884340286255\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.017730000196024776, Accuracy: 0.9950000047683716\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.611769437789917, Accuracy: 0.6153846383094788\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.012246164697280619, Accuracy: 0.9950000047683716\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 3.5142271518707275, Accuracy: 0.6225961446762085\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.010500106659019365, Accuracy: 0.9962499737739563\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 3.748441457748413, Accuracy: 0.6153846383094788\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.007369048601831309, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 4.2391438484191895, Accuracy: 0.620192289352417\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.009080372951866594, Accuracy: 0.996874988079071\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 4.122673988342285, Accuracy: 0.5817307829856873\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.007899703035691345, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 4.205833911895752, Accuracy: 0.5961538553237915\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.006138276390265674, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 4.555195331573486, Accuracy: 0.620192289352417\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.006428547148134385, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 4.69929838180542, Accuracy: 0.6033653616905212\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.007914622487951418, Accuracy: 0.996874988079071\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 3.9859135150909424, Accuracy: 0.6129807829856873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def curr_accuracy_m2(model): # определение итоговой точности модели\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for X_batch, y_batch in test_rloader:\n",
        "      out = model(X_batch)[0]\n",
        "      _, pred = torch.max(out, dim=1)\n",
        "      total += y_batch.shape[0]\n",
        "      correct += int((pred == y_batch).sum())\n",
        "  return correct/total"
      ],
      "metadata": {
        "id": "SzhOZCgJtBp-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_accuracy_m2(model_rnn) # итоговая точность"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLVPDI9xIJ5z",
        "outputId": "4c50ed0d-7776-4a96-8995-080e45cbda16"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.61"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Точность модели 61%.**"
      ],
      "metadata": {
        "id": "stG2vUy6tYWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_rnn(nn.Module):\n",
        "    \n",
        "  def __init__(self, input_size, hidden_size, n_layers, num_embeddings, n_classes, aggregate=False):\n",
        "    super(LSTM_rnn, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = n_layers\n",
        "    self.aggregate_flag = aggregate   \n",
        "\n",
        "    # загружаем предобученный эмбеддинг\n",
        "    self.embedding = nn.Embedding.from_pretrained(embeddings=torch.tensor([list(map(lambda x: float(x), row.split()[1:])) for row in open('drive/MyDrive/ML_FU/Lab_7/data/glove.6B.100d.txt').readlines()], dtype=torch.float32), freeze=False, padding_idx=0)\n",
        "    self.rnn_block = nn.LSTM(\n",
        "      input_size=input_size,\n",
        "      hidden_size=hidden_size,\n",
        "      num_layers=self.n_layers,\n",
        "      batch_first=True\n",
        "    )\n",
        "    self.fc = nn.Linear(hidden_size * self.n_layers, n_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x, h=None, c=None):\n",
        "    x = self.embedding(x)\n",
        "    if h and c:\n",
        "      all_h, (h_n, c_n) = self.rnn_block(x, (h, c))\n",
        "    else:\n",
        "      all_h, (h_n, c_n) = self.rnn_block(x)\n",
        "    h = h_n.permute(1, 0, 2)\n",
        "    if self.aggregate_flag:\n",
        "      h = torch.sum(all_h, dim=1)\n",
        "    else:\n",
        "      h = torch.flatten(h, start_dim=1, end_dim=-1)\n",
        "    classes_logits = self.fc(h)\n",
        "    return classes_logits, all_h, h_n, c_n"
      ],
      "metadata": {
        "id": "aRTkWKoDHgTn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = LSTM_rnn(\n",
        "    input_size=100,\n",
        "    hidden_size=32,\n",
        "    n_layers=1,\n",
        "    num_embeddings=len(vocab.idx_to_token),\n",
        "    n_classes=len(vocab.token_to_idx),\n",
        "    aggregate=True\n",
        ")\n",
        "optimizer_lstm = optim.Adam(model_lstm.parameters(), lr=0.001) # оптимизатор\n",
        "loss_fn = nn.CrossEntropyLoss() # функция ошибки"
      ],
      "metadata": {
        "id": "HO6dtJMoJUqW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  обучение модели\n",
        "train(100, train_rloader, test_rloader, model_lstm, loss_fn, optimizer_lstm, printing=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OQDktinJiV6",
        "outputId": "49550bf0-bc19-4043-aee3-e365c8da2b06"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.006177381951638381, Accuracy: 0.996874988079071\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 3.0776071548461914, Accuracy: 0.6586538553237915\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.007084304593445267, Accuracy: 0.996874988079071\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.796293020248413, Accuracy: 0.6490384340286255\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.004926841203559889, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.946899175643921, Accuracy: 0.6538461446762085\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.004962964605365414, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 3.0219717025756836, Accuracy: 0.6466346383094788\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.004066937662501004, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.9895970821380615, Accuracy: 0.6682692170143127\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.004565031047750381, Accuracy: 0.996874988079071\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 3.0963823795318604, Accuracy: 0.65625\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.00444805398105018, Accuracy: 0.996874988079071\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 3.4640703201293945, Accuracy: 0.6225961446762085\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.004720431905225269, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.630662679672241, Accuracy: 0.6634615659713745\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.003773400880236295, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.6899495124816895, Accuracy: 0.6658653616905212\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.004402142162107338, Accuracy: 0.9981250166893005\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.694697141647339, Accuracy: 0.6706730723381042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_accuracy_m2(model_lstm) # итоговая точность"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGKVu4v7JnD4",
        "outputId": "2e0aaca2-bb09-4e20-ea4b-cfcfc3e6c4f1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Точность модели 66%.**"
      ],
      "metadata": {
        "id": "eKDYjbPn5yqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU_rnn(nn.Module):\n",
        "    \n",
        "  def __init__(self, input_size, hidden_size, n_layers, num_embeddings, n_classes, aggregate=False):\n",
        "    super(GRU_rnn, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = n_layers\n",
        "    self.aggregate_flag = aggregate\n",
        "        \n",
        "\n",
        "    # загружаем предобученный эмбеддинг\n",
        "    self.embedding = nn.Embedding.from_pretrained(embeddings=torch.tensor([list(map(lambda x: float(x), row.split()[1:])) for row in open('drive/MyDrive/ML_FU/Lab_7/data/glove.6B.100d.txt').readlines()], dtype=torch.float32), freeze=False, padding_idx=0)\n",
        "    self.rnn_block = nn.GRU(\n",
        "      input_size=input_size,\n",
        "      hidden_size=hidden_size,\n",
        "      num_layers=self.n_layers,\n",
        "      batch_first=True\n",
        "    )\n",
        "    self.fc = nn.Linear(hidden_size * self.n_layers, n_classes)\n",
        "\n",
        "  def forward(self, x, h=None):\n",
        "    x = self.embedding(x)\n",
        "    if h:\n",
        "      all_h, h = self.rnn_block(x, (h, c))\n",
        "    else:\n",
        "      all_h, h = self.rnn_block(x)\n",
        "    h = h.permute(1, 0, 2)\n",
        "    if self.aggregate_flag:\n",
        "      h = torch.sum(all_h, dim=1)\n",
        "    else:\n",
        "      h = torch.flatten(h, start_dim=1, end_dim=-1)\n",
        "    classes_logits = self.fc(h)\n",
        "    return classes_logits, all_h, h"
      ],
      "metadata": {
        "id": "tAmHipF6JqVZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = GRU_rnn(\n",
        "    input_size=100,\n",
        "    hidden_size=32,\n",
        "    n_layers=1,\n",
        "    num_embeddings=len(vocab.idx_to_token),\n",
        "    n_classes=len(vocab.token_to_idx),\n",
        "    aggregate=True\n",
        ")\n",
        "optimizer_gru = optim.Adam(model_gru.parameters(), lr=0.001) # оптимизатор\n",
        "loss_fn = nn.CrossEntropyLoss() # функция ошибки"
      ],
      "metadata": {
        "id": "L8bHEYhmLT2a"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(100, train_rloader, test_rloader, model_gru, loss_fn, optimizer_gru, printing=10) # обучаем модель "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-5mfb66LgrX",
        "outputId": "c64ce142-5437-46e4-c6a2-192b2e900fa4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.06738208796828986, Accuracy: 0.9868749976158142\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.2541390657424927, Accuracy: 0.6418269276618958\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.014703454421833158, Accuracy: 0.9950000047683716\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.6005685329437256, Accuracy: 0.6682692170143127\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.009154227080289274, Accuracy: 0.996874988079071\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.1719167232513428, Accuracy: 0.6586538553237915\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.006034274957492016, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.915507197380066, Accuracy: 0.6658653616905212\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.00980524693208281, Accuracy: 0.9956250190734863\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.1456961631774902, Accuracy: 0.6490384340286255\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.005037465911591425, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.3511955738067627, Accuracy: 0.65625\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.005451616944483249, Accuracy: 0.9981250166893005\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.9328749179840088, Accuracy: 0.6418269276618958\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.007532393481815234, Accuracy: 0.996874988079071\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.8770592212677002, Accuracy: 0.6634615659713745\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.007038224539282965, Accuracy: 0.9975000023841858\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 2.0460598468780518, Accuracy: 0.6778846383094788\n",
            "________________________________________\n",
            "Train:\n",
            "Loss: 0.005560821789840702, Accuracy: 0.996874988079071\n",
            "----------------------------------------\n",
            "Test:\n",
            "Loss: 1.895432949066162, Accuracy: 0.6706730723381042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr_accuracy_m2(model_gru) # итоговая точность"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6GWrlZYLnBx",
        "outputId": "3ea2b82b-c13a-42ab-f19c-62f49d021233"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Точноть составила 67%.**"
      ],
      "metadata": {
        "id": "cCo_7m_CGsNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({'name': ['RNN', 'LSTM', 'GRU'], 'accuracy': [curr_accuracy_m2(model_rnn), curr_accuracy_m2(model_lstm), curr_accuracy_m2(model_gru)]})\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "aai0UNSqMB5p",
        "outputId": "22f926a9-a52e-4bbc-c16a-e61624004aab"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   name  accuracy\n",
              "0   RNN    0.6100\n",
              "1  LSTM    0.6625\n",
              "2   GRU    0.6725"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e67fcbe-1f33-4a32-822e-0bd629718192\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RNN</td>\n",
              "      <td>0.6100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>0.6625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GRU</td>\n",
              "      <td>0.6725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e67fcbe-1f33-4a32-822e-0bd629718192')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e67fcbe-1f33-4a32-822e-0bd629718192 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e67fcbe-1f33-4a32-822e-0bd629718192');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод\n",
        "После обучения моделей можем сделать вывод, что лучшая из них - GRU, точность которой составила 67%, является более простой версией сетей долгой краткосрочной памяти (LSTM). При одинаковом размере скрытого слоя обучается быстрее, потому что имеет куда меньше параметров.\n",
        "\n",
        "Хуже всего показала себя модель RNN, результат которой: точность = 61% ."
      ],
      "metadata": {
        "id": "4EhTp_rBG0-6"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Jm-QilGISxkt",
        "a8jKuMq5eHu8",
        "_v8_vcAa8Jqy"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}